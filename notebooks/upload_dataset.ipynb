{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc4bb20d-67d5-491e-87a0-759385c066b4",
   "metadata": {},
   "source": [
    "Start by making sure you have the following packages in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87978de2-a30c-48e3-9408-f5f57b9dfc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install huggingface_hub datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848964bd-da4b-41b5-b64b-f07040816950",
   "metadata": {},
   "outputs": [],
   "source": [
    "MANIFEST_PATH = \"../dataset/output/manifests.json\"\n",
    "MY_DATASET = \"janaab/supreme-court-speech\" ## <user-name>/<dataset-name>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e549ed-61aa-4958-b8e4-4db8f20f5544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "segments = []\n",
    "with open(MANIFEST_PATH, 'r') as file:\n",
    "    for line in file:\n",
    "        seg = json.loads(line)\n",
    "        segments.append(seg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad23733a-a39e-457a-84e9-339b4fa2052f",
   "metadata": {},
   "source": [
    "Check out a few stats on the dataset you have right now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bd25c9-2707-45a8-a56d-341e651c1c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_duration(segments):\n",
    "    return sum([seg[\"duration\"] for seg in segments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4b0ec7-0c88-449f-ae63-7b0587f63c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = -2.0\n",
    "clean_segments = [seg for seg in segments if seg[\"score\"]>=THRESHOLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed8496a-03c6-4b7e-839f-c099338520a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration(segments)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac32ee7d-4d42-45b3-8061-2962505a0d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration(clean_segments)/3600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "210f3e69-1e50-4f37-b11e-2ab003a211e9",
   "metadata": {},
   "source": [
    "## HF Dataset\n",
    "\n",
    "Create train and test splits, and upload to HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8203c55-b495-4c5b-a55c-4aea0233ee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def split_segments_by_duration_and_length(segments, train_ratio=0.7):\n",
    "    # Calculate total duration and length\n",
    "    total_duration = sum(segment['duration'] for segment in segments)\n",
    "    total_length = len(segments)\n",
    "    \n",
    "    # Determine the split thresholds\n",
    "    train_duration_threshold = train_ratio * total_duration\n",
    "    train_length_threshold = int(train_ratio * total_length)\n",
    "    \n",
    "    # Shuffle segments to randomize order\n",
    "    random.shuffle(segments)\n",
    "    \n",
    "    # Initialize accumulators and split lists\n",
    "    train_list = []\n",
    "    test_list = []\n",
    "    accumulated_duration = 0\n",
    "    num_train_segments = 0\n",
    "    \n",
    "    # Accumulate segments for the train split\n",
    "    for segment in segments:\n",
    "        if (accumulated_duration + segment['duration'] <= train_duration_threshold and\n",
    "            num_train_segments + 1 <= train_length_threshold):\n",
    "            train_list.append(segment)\n",
    "            accumulated_duration += segment['duration']\n",
    "            num_train_segments += 1\n",
    "        else:\n",
    "            test_list.append(segment)\n",
    "    \n",
    "    return train_list, test_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d24135-34f0-4d90-a365-7f1a55d18e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_segments_by_duration_and_length(clean_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "204e2216-30d5-4b15-9c61-6f1ab29f6c7e",
   "metadata": {},
   "source": [
    "Again, some stats on your dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e067f-3dfd-4312-bd46-afb63eb3d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration(train)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb9dc2-e17d-4ab3-a3b3-4b83d0acc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_duration(test)/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d17c0a-ca55-4a23-8ef1-7f121c1aba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6967370-7fca-4da7-8092-d32a9173f020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, Audio\n",
    "\n",
    "def create_dataset(segments):\n",
    "    data = {\n",
    "        \"audio\": [seg[\"audio_filepath\"] for seg in segments],\n",
    "        \"transcript\": [seg[\"text\"] for seg in segments],\n",
    "        \"duration\": [seg[\"duration\"] for seg in segments]\n",
    "    }\n",
    "    dataset = Dataset.from_dict(data).cast_column(\"audio\", Audio())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd39624b-20a9-46e0-b81a-d9cd6d2ddfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': create_dataset(train),\n",
    "    'test': create_dataset(test)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb01d82-36c1-44a4-8cca-eeb5b4472fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to HF hub\n",
    "\n",
    "from huggingface_hub import interpreter_login\n",
    "# interpreter_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93894dc2-15db-487e-95ca-f020e8794bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload to HF\n",
    "dataset_dict.push_to_hub(MY_DATASET)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
