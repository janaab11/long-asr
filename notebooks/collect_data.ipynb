{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2721fa33-26bc-40eb-9ecc-fcd6ab779b22",
   "metadata": {},
   "source": [
    "Start by making sure you have the following packages in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1d8e571-1629-4c2b-b085-e96b269ec87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tqdm pandas pdfplumber requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eed7a2a-bd79-4582-a03e-436bd5277ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA = \"../data/sc_speech.csv\"\n",
    "DATA_DIR = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f16c869-17e5-4962-bc83-c2da18fff4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "AUDIO_DIR = os.path.join(DATA_DIR, \"audio\")\n",
    "TEXT_DIR = os.path.join(DATA_DIR, \"text\")\n",
    "\n",
    "! mkdir -p $AUDIO_DIR $TEXT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "341b6db9-0d18-42f6-b542-1415917d27f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.output_area pre {max-height: 100px; overflow-y: scroll;}</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "# Set a maximum height for all output areas\n",
    "display(HTML('''<style>.output_area pre {max-height: 100px; overflow-y: scroll;}</style>'''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46dad89-bbc1-455c-9f33-14771317e984",
   "metadata": {},
   "source": [
    "## Cleaning transcripts\n",
    "\n",
    "Download transcripts and format into dialog format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0a3d471-2aa3-4e41-a543-0ddfccf60e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import requests\n",
    "import pdfplumber\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e45e1a4b-ef93-491a-b637-65678c369a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcript:\n",
    "    def __init__(self, url, debug=False):\n",
    "        self.debug = debug\n",
    "        self.time = time.time()\n",
    "        self.doc = self.__get_pdf(url)\n",
    "        self.lines = self.__parse_doc()\n",
    "\n",
    "    def __log_time(self, key):\n",
    "        if self.debug:\n",
    "            elapsed_time = time.time() - self.time\n",
    "            print(f\"{key}: {elapsed_time:.2f} seconds\")\n",
    "        self.time = time.time()\n",
    "\n",
    "    def __get_pdf(self, pdf_url):\n",
    "        response = requests.get(pdf_url)\n",
    "        response.raise_for_status()\n",
    "        doc = pdfplumber.open(BytesIO(response.content))\n",
    "        self.__log_time(\"download pdf\")\n",
    "        return doc\n",
    "\n",
    "    def __parse_doc(self):\n",
    "        SKIP_LIST = [\"IST\", \"LIVE FEED\", \"END OF\", \"Transcribed by\"]\n",
    "        number_pattern = re.compile(r'^\\d+\\s?')\n",
    "        lines = []\n",
    "\n",
    "        # skip first page of every document, as irrelevant\n",
    "        for page in self.doc.pages[1:]:\n",
    "            text = page.extract_text().strip()\n",
    "            for line in text.split('\\n'):\n",
    "                # clean line numbers\n",
    "                clean_line = number_pattern.sub('', line)\n",
    "                \n",
    "                # skip lines that are not relevant\n",
    "                if clean_line and all(key not in clean_line for key in SKIP_LIST):\n",
    "                    lines.append(clean_line)\n",
    "\n",
    "        self.__log_time(\"parse pdf\")\n",
    "        return lines\n",
    "\n",
    "    def format(self):\n",
    "        SEP = \": \"\n",
    "        speakers = []\n",
    "        transcript = []\n",
    "\n",
    "        for line in self.lines:\n",
    "            if SEP in line:\n",
    "                speaker, text = line.split(SEP, 1)\n",
    "                if speaker not in speakers:\n",
    "                    speakers.append(speaker)\n",
    "                transcript.append({\"speaker\": speaker, \"text\": text})\n",
    "            else:\n",
    "                transcript[-1][\"text\"] = f\"{transcript[-1]['text']} {line}\"\n",
    "\n",
    "        self.__log_time(\"format\")\n",
    "        return transcript\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db3107a8-d4df-4242-97f8-b58221d9df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(RAW_DATA)\n",
    "data.drop(data.tail(1).index,inplace=True) # drop last empty row\n",
    "# data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6a95020-480e-4afc-b12a-995a114beec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TEST\n",
    "\n",
    "# urls = data[\"Transcript Link\"].to_list()\n",
    "# transcript = Transcript(urls[14], debug=True).format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57cae260-0868-4439-b635-72ade95948fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # KEYWORD SPOTTING\n",
    "\n",
    "# pattern = re.compile(r'\\b[A-Z]{2,}(?:\\s+[A-Z]{2,})*\\b')\n",
    "# for t in transcript:\n",
    "#     finds = pattern.findall(t[\"text\"])\n",
    "#     if len(finds)>0:\n",
    "#         print(finds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f9bfda0-d173-4255-af03-d3ec3b565108",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [04:36<00:00, 11.52s/it]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "data[\"transcript\"] = data[\"Transcript Link\"].progress_apply(lambda url: json.dumps(Transcript(url, debug=False).format()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14b700b-146d-4e88-8fe9-fb57e731659f",
   "metadata": {},
   "source": [
    "Format transcripts into text strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17604d84-8146-4ef2-ac75-851db4979fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean and format to optimise for segment quality\n",
    "\n",
    "def clean_transcript(transcript):    \n",
    "    \n",
    "    # replace ellipsis by stop token\n",
    "    # replace stop tokens by semi-colon\n",
    "    def clean_text(text):\n",
    "        pattern = re.compile(r'\\.\\.+')\n",
    "        return pattern.sub(\".\", text.rstrip(\".\")).replace(\"…\",\".\").replace(\".\", \";\")\n",
    "    \n",
    "    text = clean_text(transcript[0][\"text\"])\n",
    "    for t in transcript[1:]:\n",
    "        sample = clean_text(t[\"text\"])\n",
    "        # add stop token between speaker changes\n",
    "        text = \". \".join([text, sample])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0875bb54-5c44-4a51-8387-95cd53234250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Sr. No.', 'Case Name', 'Case Number', 'Hearing Date',\n",
       "       'Transcript Link', 'Oral Hearing Link', 'Hearing Duration(in Minutes)',\n",
       "       'mp3 format link', 'transcript', 'text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"] = data[\"transcript\"].apply(lambda transcript: json.dumps(clean_transcript(json.loads(transcript))))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fc644-1658-4986-b249-a65f01a46fa8",
   "metadata": {},
   "source": [
    "## Preparing data\n",
    "\n",
    "Prepare data for segmentation - audios and texts are stored in a specific directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5800c4f-562a-42b5-8616-07651579a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = list(zip(data[\"mp3 format link\"], data[\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b55d22b3-7d9d-4f67-90ee-2ba223170ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def download_and_write(sample, i):\n",
    "    url, text = sample\n",
    "    \n",
    "    # Download audio\n",
    "    audio_file = f'{AUDIO_DIR}/{i}.wav'\n",
    "    ! rm -rf $audio_file\n",
    "    ! wget -qO- \"$url\" | ffmpeg -i pipe:0 -ac 1 $audio_file -loglevel error -y\n",
    "    \n",
    "    # Write text\n",
    "    text_file = f'{TEXT_DIR}/{i}.txt'\n",
    "    with open(text_file, 'w') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# spread downloads across threads\n",
    "def parallel_download(samples):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(download_and_write, samples, range(len(samples))), total=len(samples)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f2a8d9fa-d2d3-4133-afea-c5a6c19a40ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24/24 [01:05<00:00,  2.72s/it]\n"
     ]
    }
   ],
   "source": [
    "parallel_download(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f277e1-faba-42aa-8270-2653ad40e080",
   "metadata": {},
   "source": [
    "\n",
    "--DATA_DIR\n",
    "\n",
    "     |----audio\n",
    "            |---1.wav\n",
    "            |---2.wav\n",
    "            \n",
    "     |-----text\n",
    "            |---1.txt\n",
    "            |---2.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
