{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e9b77ce-fc15-4b41-a954-5d0ae26fc6ce",
   "metadata": {},
   "source": [
    "Start by making sure you have the following packages in your environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89702a-866a-47a7-b29b-1fc07a79c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install evaluate datasets transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5519b71a-236a-4835-a17b-68788aaa858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_DATASET = \"janaab/supreme-court-speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a9430b-d2c9-42c6-973a-90f2c04aaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL = \"openai/whisper-small\"\n",
    "TUNED_MODEL = \"janaab/whisper-small-sc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c9b71c-7126-4cb7-8e96-e2c1b2e88f44",
   "metadata": {},
   "source": [
    "## Load data and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76d9414-b0f8-46ff-b315-ff045cfe8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sc_speech = load_dataset(\n",
    "    EVAL_DATASET, split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a870663-6783-4d87-b589-a707efdd5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "    torch_dtype = torch.float16\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    torch_dtype = torch.float32\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=BASE_MODEL,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75998cbc-b42b-47f2-b9ea-2445a201e087",
   "metadata": {},
   "source": [
    "## Generate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069577b-1e5c-43c0-a2c6-4068caf811c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "all_predictions = []\n",
    "\n",
    "# run streamed inference\n",
    "for prediction in tqdm(\n",
    "    pipe(\n",
    "        KeyDataset(sc_speech, \"audio\"),\n",
    "        max_new_tokens=128,\n",
    "        generate_kwargs={\"task\": \"transcribe\"},\n",
    "        batch_size=32,\n",
    "    ),\n",
    "    total=len(sc_speech),\n",
    "):\n",
    "    all_predictions.append(prediction[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4413e8-7c1d-44f0-9e4f-75b942dfddee",
   "metadata": {},
   "source": [
    "## Evaluate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8fce1-5feb-409b-8186-52a1f254e4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "\n",
    "wer_metric = load(\"wer\")\n",
    "\n",
    "wer_ortho = 100 * wer_metric.compute(\n",
    "    references=sc_speech[\"transcript\"], predictions=all_predictions\n",
    ")\n",
    "wer_ortho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214a3ad4-80a0-4d51-9bca-ec4a7b454d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.whisper.english_normalizer import BasicTextNormalizer\n",
    "\n",
    "normalizer = BasicTextNormalizer()\n",
    "\n",
    "# compute normalised WER\n",
    "all_predictions_norm = [normalizer(pred) for pred in all_predictions]\n",
    "all_references_norm = [normalizer(label) for label in sc_speech[\"transcript\"]]\n",
    "\n",
    "# filtering step to only evaluate the samples that correspond to non-zero references\n",
    "all_predictions_norm = [\n",
    "    all_predictions_norm[i]\n",
    "    for i in range(len(all_predictions_norm))\n",
    "    if len(all_references_norm[i]) > 0\n",
    "]\n",
    "all_references_norm = [\n",
    "    all_references_norm[i]\n",
    "    for i in range(len(all_references_norm))\n",
    "    if len(all_references_norm[i]) > 0\n",
    "]\n",
    "\n",
    "wer = 100 * wer_metric.compute(\n",
    "    references=all_references_norm, predictions=all_predictions_norm\n",
    ")\n",
    "\n",
    "wer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
